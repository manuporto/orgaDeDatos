{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('juan', ['carlos', 'olaf'], ['ezequiel', 'tomas']), ('tomas', ['carlos'], ['ezequiel']), ('ezequiel', ['olaf'], ['juan', 'carlos'])]\n",
      "('ezequiel', 2)\n"
     ]
    }
   ],
   "source": [
    "from operator import add\n",
    "# Parcial 2014 1C 2 oportunidad\n",
    "data = [('juan', ['carlos', 'olaf'], ['ezequiel', 'tomas']), \n",
    "        ('tomas', ['carlos'], ['ezequiel']), ('ezequiel', ['olaf'], ['juan', 'carlos'])]\n",
    "rdd = sc.parallelize(data, 4)\n",
    "print(rdd.collect())\n",
    "enemy = rdd.flatMap(lambda x: [(i, 1) for i in x[2]]).reduceByKey(add).reduce(lambda x, y: x if x[1] > y[1] else y)\n",
    "print(enemy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2016-01 Parcial\n",
    "\n",
    "UBER almacena en un cluster todos los datos sobre el movimiento y viajes de todos sus vehículos. Existe un proceso que nos devuelve un RDD llamado trip_summary con los siguientes campos: (driver_id, car_id, trip_id, customer_id, date (YYYYMMDD), distance_traveled), Programar usando Py Spark un programa que nos indique cual fue el conductor con mayor promedio de distancia recorrida por viaje para Abril de 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 32)\n",
      "[(1, 17.5), (2, 32.5), (3, 15.0)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('a', (2, 4)), ('b', (1, 2))]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trips = [\n",
    "    (1, 1, 1, 1, '20160101', 10),\n",
    "    (2, 2, 2, 2, '20160202', 20),\n",
    "    (1, 1, 3, 1, '20160402', 15),\n",
    "    (1, 1, 4, 3, '20160405', 20),\n",
    "    (2, 2, 5, 4, '20160410', 25),\n",
    "    (3, 3, 6, 3, '20160415', 15),\n",
    "    (2, 2, 7, 1, '20160420', 40),\n",
    "    (3, 3, 8, 2, '20160505', 80)\n",
    "]\n",
    "rdd = sc.parallelize(trips)\n",
    "print(rdd.filter(lambda x: (x[4] > '20160400') and (x[4] < '20160500'))\\\n",
    "    .map(lambda x: (x[0], (1, x[5])))\\\n",
    "    .reduceByKey(lambda x, y: (x[0] + y[0], x[1] + y[1]))\\\n",
    "    .map(lambda x: (x[0], x[1][1]/x[1][0]))\\\n",
    "    .reduce(lambda x, y: x if x[1] > y[1] else y))\n",
    "\n",
    "print(rdd.filter(lambda x: x[4] > '20160400' and x[4] < '20160500').map(lambda x: (x[0], (x[5], 1))).\\\n",
    "      reduceByKey(lambda x, y: (x[0]+y[0], x[1] + y[1]) ).\\\n",
    "      map(lambda x: (x[0], float(x[1][0])/x[1][1])).collect())#reduce(lambda x, y: x if x[1] > y[1] else y))\n",
    "      #reduce(lambda x, y: x if (x[1][0]/x[1][1]) > (y[1][0]/y[1][0]) else y))\n",
    "rdd = sc.parallelize([(\"a\", (1, 2)), (\"b\", (1, 2)), (\"a\", (1, 2))])\n",
    "sorted(rdd.reduceByKey(lambda x, y: (x[0]+y[0], x[1] + y[1])).collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2015-02 2do Recuperatorio\n",
    "\n",
    "Un telescopio registra automaticamente la luminosidad de distintas estrellas generando un RDD con registros de tipo (star_id, magnitude,spectral_type, timestamp). Queremos obtener un listado de estrellas que tienen el mismo tipo espectral e igual promedio de magnitud una vez redondeado el mismo a un decimal. El resultado debe ser una lista en donde cada elemento de la lista es una lista de ids de estrellas similares.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(4, (2, 5.5, 1)), (1, (1, 16.5, 3)), (2, (1, 30, 3)), (3, (1, 16.5, 3))]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[((2, 5.5), [4]), ((1, 10), [2]), ((1, 5.5), [1, 3])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stars = [\n",
    "    (1, 5, 1, 1),\n",
    "    (2, 10, 1, 1),\n",
    "    (3, 6, 1, 1),\n",
    "    (4, 5.5, 2, 1),\n",
    "    (1, 6, 1, 2),\n",
    "    (2, 9, 1, 2),\n",
    "    (3, 5, 1, 2),\n",
    "    (1, 5.5, 1, 3),\n",
    "    (2, 11, 1, 3),\n",
    "    (3, 5.5, 1, 3)\n",
    "]\n",
    "rdd = sc.parallelize(stars)\n",
    "rdd = rdd.map(lambda x: (x[0], (x[2], x[1], 1))).reduceByKey(lambda x, y: (x[0], x[1] + y[1],x[2] + y[2]))\n",
    "    #map(lambda x: (x[0], (x[1][0], float(\"{0:.1f}\".format(x[1][1]/len(x[1][0])))))).\\\n",
    "    #flatMap(lambda x: [(i, (x[0], x[1][1])) for i in x[1][0]])#\\\n",
    "    #.reduceByKey(lambda x, y: (x[0] + y[0]))\n",
    "print(rdd.collect())\n",
    "\n",
    "# Catedra\n",
    "\n",
    "data = sc.parallelize(stars)\n",
    "data.map(lambda x: (x[0], (x[2], x[1], 1)))\\\n",
    "    .reduceByKey(lambda x, y: (x[0], x[1]+y[1], x[2]+y[2]))\\\n",
    "    .map(lambda x: ((x[1][0], x[1][1]/x[1][2]), x[0]))\\\n",
    "    .groupByKey()\\\n",
    "    .map(lambda x: (x[0], list(x[1])))\\\n",
    "    .collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 2014-01 Parcial\n",
    "\n",
    "Se tiene un archivo con información sobre visitas a páginas\n",
    "web de la forma: (URL, visitas, fecha). Existe solo un registro\n",
    "por día para cada URL. Se quiere generar un archivo que, por\n",
    "cada URL, indique cuál fue la fecha en la que tuvo mas visitas\n",
    "y la cantidad de visitas.\n",
    "Programar lo pedido en Map Reduce usando agregación para\n",
    "minimizar la cantidad de datos que deben transferirse en la\n",
    "red.\n",
    "Atención: La resolución es muy simple, trivial, asi que es\n",
    "fundamental resolver la agregación para el puntaje completo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('example.org', (10, '20160401')),\n",
       " ('example.net', (3, '20160101')),\n",
       " ('google.com', (13, '20160202')),\n",
       " ('archlinux.org', (7, '20160111'))]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [('example.net', 3, '20160101'),\n",
    "       ('example.org', 1, '20160205'),\n",
    "       ('google.com', 13, '20160202'),\n",
    "       ('example.org', 9, '20160103'),\n",
    "       ('archlinux.org', 7, '20160111'),\n",
    "       ('example.net', 0, '20160121'),\n",
    "       ('example.org', 10, '20160401'),\n",
    "       ('archlinux.org', 3, '20160119'),\n",
    "       ('google.com', 2, '20160128')]\n",
    "\n",
    "rdd = sc.parallelize(data)\n",
    "rdd.map(lambda x: (x[0], [(x[1], x[2])])).reduceByKey(lambda x, y: x+y).map(lambda x: (x[0], max(x[1]))).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2015-01 2do Recuperatorio\n",
    "Tenemos una colección de documentos (textos) almacenados en un cluster. Se quiere establecer un ranking de los patrones mas frecuentes para la aparición de letras en las palabras. Por ejemplo “sister”, “ejects” , “ninety” y “amazon” responden al patrón “abacde”. Programar en map-reduce un programa que genere como resultado un listado de tipo (patron, frecuencia) indicando cuántas veces aparece cada patrón en la colección de documentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('abcde', 3),\n",
       " ('abc', 3),\n",
       " ('a', 2),\n",
       " ('abcd', 1),\n",
       " ('abacde', 1),\n",
       " ('abcdefegbhifjkeedl', 1),\n",
       " ('ab', 1),\n",
       " ('abcdefag', 1),\n",
       " ('abcdeb', 1)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def patron(palabra):\n",
    "    letras = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    ind = 0\n",
    "    letra = letras[ind]\n",
    "    usadas = {}\n",
    "    patron = ''\n",
    "    for i in palabra:\n",
    "        if i not in usadas.keys():\n",
    "            usadas[i] = letra\n",
    "            ind += 1\n",
    "            letra = letras[ind]\n",
    "        patron += usadas[i]\n",
    "    return patron\n",
    "\n",
    "\n",
    "rdd = sc.textFile('foo.txt')\n",
    "rdd.flatMap(lambda x: x.split()).map(lambda x: (patron(x), 1)).reduceByKey(lambda x, y: x+y)\\\n",
    ".takeOrdered(10, lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('abcde', 3),\n",
       " ('abc', 3),\n",
       " ('a', 2),\n",
       " ('abcd', 1),\n",
       " ('abacde', 1),\n",
       " ('abcdefegbhifjkeedl', 1),\n",
       " ('ab', 1),\n",
       " ('abcdefag', 1),\n",
       " ('abcdeb', 1)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textFile = sc.textFile(\"foo.txt\")\n",
    "words = textFile.flatMap(lambda line: line.split())\n",
    "words.collect()\n",
    "def pattern(word):\n",
    "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    pat = ''\n",
    "    found = ''\n",
    "    for letter in word:\n",
    "        if letter in found:\n",
    "            pat += pat[found.index(letter)]\n",
    "        else:\n",
    "            found += letter\n",
    "            if len(found) > len(letters):\n",
    "                pat += '?'\n",
    "            else:\n",
    "                pat += letters[len(found)-1]\n",
    "    return pat\n",
    "   \n",
    "words.map(lambda x: (pattern(x), 1))\\\n",
    "     .reduceByKey(lambda x, y: x+y)\\\n",
    "     .takeOrdered(10, lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2015-02-2op\n",
    "Se tiene un RDD con libros en donde cada registro es un texto. Se\n",
    "pide obtener todos los anagramas de mas de 7 letras que puedan\n",
    "encontrarse. El formato de salida debe ser una lista de listas en donde\n",
    "cada lista tiene un conjunto de palabras que son anagramas. Ejemplo:\n",
    "[[discounter,introduces,reductions],[percussion,supersonic]...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'a2e3n2o1r1', [u'aeneanero']),\n",
       " (u'c1d1i2n2t2u1', [u'tincidunt']),\n",
       " (u'e2f1m2n1r1t1u1', [u'fermuentm', u'fermentum', u'fermtunme']),\n",
       " (u'c1e1i2l1r1s1t1u1', [u'ultricies']),\n",
       " (u'c1d1e1i1m2n2o1t1u1', [u'condimentum', u'condimentum']),\n",
       " (u'b1e1i1l1m1s1t1u2v1', [u'vestibulum'])]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def anagrama(x):\n",
    "    res = {}\n",
    "    for i in x:\n",
    "        res[i] = res.get(i, 0) + 1\n",
    "    anagrama = ''\n",
    "    for letra, cant in sorted(res.items()):\n",
    "        anagrama += letra+str(cant)\n",
    "    return anagrama\n",
    "\n",
    "text = sc.textFile('bar.txt')\n",
    "text.flatMap(lambda x: x.split()).filter(lambda x: len(x) > 7)\\\n",
    "    .map(lambda x: (anagrama(x), x)).groupByKey().map(lambda x: (x[0], list(x[1]))).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
