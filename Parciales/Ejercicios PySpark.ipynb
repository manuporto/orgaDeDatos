{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2014-01-2op\n",
    "Se tiene un archivo distribuido con información de una red\n",
    "social en la cual cada registro  tiene información  sobre un\n",
    "usuario y una lista de sus amigos y sus enemigos (user_id,\n",
    "vector_ids_amigos,vector_ids_enemigos). Queremos encontrar\n",
    "al   usuario   que   figura   en   mas   listas   de   enemigos,   para\n",
    "designarlo el enemigo público número un"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('juan', ['carlos', 'olaf'], ['ezequiel', 'tomas']), ('tomas', ['carlos'], ['ezequiel']), ('ezequiel', ['olaf'], ['juan', 'carlos'])]\n",
      "('ezequiel', 2)\n"
     ]
    }
   ],
   "source": [
    "from operator import add\n",
    "data = [('juan', ['carlos', 'olaf'], ['ezequiel', 'tomas']), \n",
    "        ('tomas', ['carlos'], ['ezequiel']), ('ezequiel', ['olaf'], ['juan', 'carlos'])]\n",
    "rdd = sc.parallelize(data, 4)\n",
    "print(rdd.collect())\n",
    "enemy = rdd.flatMap(lambda x: [(i, 1) for i in x[2]]).reduceByKey(add).reduce(lambda x, y: x if x[1] > y[1] else y)\n",
    "print(enemy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2016-01 Parcial\n",
    "\n",
    "UBER almacena en un cluster todos los datos sobre el movimiento y viajes de todos sus vehículos. Existe un proceso que nos devuelve un RDD llamado trip_summary con los siguientes campos: (driver_id, car_id, trip_id, customer_id, date (YYYYMMDD), distance_traveled), Programar usando Py Spark un programa que nos indique cual fue el conductor con mayor promedio de distancia recorrida por viaje para Abril de 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 32)\n",
      "[(1, 17.5), (2, 32.5), (3, 15.0)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('a', (2, 4)), ('b', (1, 2))]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trips = [\n",
    "    (1, 1, 1, 1, '20160101', 10),\n",
    "    (2, 2, 2, 2, '20160202', 20),\n",
    "    (1, 1, 3, 1, '20160402', 15),\n",
    "    (1, 1, 4, 3, '20160405', 20),\n",
    "    (2, 2, 5, 4, '20160410', 25),\n",
    "    (3, 3, 6, 3, '20160415', 15),\n",
    "    (2, 2, 7, 1, '20160420', 40),\n",
    "    (3, 3, 8, 2, '20160505', 80)\n",
    "]\n",
    "rdd = sc.parallelize(trips)\n",
    "print(rdd.filter(lambda x: (x[4] > '20160400') and (x[4] < '20160500'))\\\n",
    "    .map(lambda x: (x[0], (1, x[5])))\\\n",
    "    .reduceByKey(lambda x, y: (x[0] + y[0], x[1] + y[1]))\\\n",
    "    .map(lambda x: (x[0], x[1][1]/x[1][0]))\\\n",
    "    .reduce(lambda x, y: x if x[1] > y[1] else y))\n",
    "\n",
    "print(rdd.filter(lambda x: x[4] > '20160400' and x[4] < '20160500').map(lambda x: (x[0], (x[5], 1))).\\\n",
    "      reduceByKey(lambda x, y: (x[0]+y[0], x[1] + y[1]) ).\\\n",
    "      map(lambda x: (x[0], float(x[1][0])/x[1][1])).collect())#reduce(lambda x, y: x if x[1] > y[1] else y))\n",
    "      #reduce(lambda x, y: x if (x[1][0]/x[1][1]) > (y[1][0]/y[1][0]) else y))\n",
    "rdd = sc.parallelize([(\"a\", (1, 2)), (\"b\", (1, 2)), (\"a\", (1, 2))])\n",
    "sorted(rdd.reduceByKey(lambda x, y: (x[0]+y[0], x[1] + y[1])).collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2015-02 2do Recuperatorio\n",
    "\n",
    "Un telescopio registra automaticamente la luminosidad de distintas estrellas generando un RDD con registros de tipo (star_id, magnitude,spectral_type, timestamp). Queremos obtener un listado de estrellas que tienen el mismo tipo espectral e igual promedio de magnitud una vez redondeado el mismo a un decimal. El resultado debe ser una lista en donde cada elemento de la lista es una lista de ids de estrellas similares.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(4, (2, 5.5, 1)), (1, (1, 16.5, 3)), (2, (1, 30, 3)), (3, (1, 16.5, 3))]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[((2, 5.5), [4]), ((1, 10), [2]), ((1, 5.5), [1, 3])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stars = [\n",
    "    (1, 5, 1, 1),\n",
    "    (2, 10, 1, 1),\n",
    "    (3, 6, 1, 1),\n",
    "    (4, 5.5, 2, 1),\n",
    "    (1, 6, 1, 2),\n",
    "    (2, 9, 1, 2),\n",
    "    (3, 5, 1, 2),\n",
    "    (1, 5.5, 1, 3),\n",
    "    (2, 11, 1, 3),\n",
    "    (3, 5.5, 1, 3)\n",
    "]\n",
    "rdd = sc.parallelize(stars)\n",
    "rdd = rdd.map(lambda x: (x[0], (x[2], x[1], 1))).reduceByKey(lambda x, y: (x[0], x[1] + y[1],x[2] + y[2]))\n",
    "    #map(lambda x: (x[0], (x[1][0], float(\"{0:.1f}\".format(x[1][1]/len(x[1][0])))))).\\\n",
    "    #flatMap(lambda x: [(i, (x[0], x[1][1])) for i in x[1][0]])#\\\n",
    "    #.reduceByKey(lambda x, y: (x[0] + y[0]))\n",
    "print(rdd.collect())\n",
    "\n",
    "# Catedra\n",
    "\n",
    "data = sc.parallelize(stars)\n",
    "data.map(lambda x: (x[0], (x[2], x[1], 1)))\\\n",
    "    .reduceByKey(lambda x, y: (x[0], x[1]+y[1], x[2]+y[2]))\\\n",
    "    .map(lambda x: ((x[1][0], x[1][1]/x[1][2]), x[0]))\\\n",
    "    .groupByKey()\\\n",
    "    .map(lambda x: (x[0], list(x[1])))\\\n",
    "    .collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 2014-01 Parcial\n",
    "\n",
    "Se tiene un archivo con información sobre visitas a páginas\n",
    "web de la forma: (URL, visitas, fecha). Existe solo un registro\n",
    "por día para cada URL. Se quiere generar un archivo que, por\n",
    "cada URL, indique cuál fue la fecha en la que tuvo mas visitas\n",
    "y la cantidad de visitas.\n",
    "Programar lo pedido en Map Reduce usando agregación para\n",
    "minimizar la cantidad de datos que deben transferirse en la\n",
    "red.\n",
    "Atención: La resolución es muy simple, trivial, asi que es\n",
    "fundamental resolver la agregación para el puntaje completo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('example.org', (10, '20160401')),\n",
       " ('example.net', (3, '20160101')),\n",
       " ('google.com', (13, '20160202')),\n",
       " ('archlinux.org', (7, '20160111'))]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [('example.net', 3, '20160101'),\n",
    "       ('example.org', 1, '20160205'),\n",
    "       ('google.com', 13, '20160202'),\n",
    "       ('example.org', 9, '20160103'),\n",
    "       ('archlinux.org', 7, '20160111'),\n",
    "       ('example.net', 0, '20160121'),\n",
    "       ('example.org', 10, '20160401'),\n",
    "       ('archlinux.org', 3, '20160119'),\n",
    "       ('google.com', 2, '20160128')]\n",
    "\n",
    "rdd = sc.parallelize(data)\n",
    "rdd.map(lambda x: (x[0], [(x[1], x[2])])).reduceByKey(lambda x, y: x+y).map(lambda x: (x[0], max(x[1]))).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2015-01 2do Recuperatorio\n",
    "Tenemos una colección de documentos (textos) almacenados en un cluster. Se quiere establecer un ranking de los patrones mas frecuentes para la aparición de letras en las palabras. Por ejemplo “sister”, “ejects” , “ninety” y “amazon” responden al patrón “abacde”. Programar en map-reduce un programa que genere como resultado un listado de tipo (patron, frecuencia) indicando cuántas veces aparece cada patrón en la colección de documentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('abcde', 3),\n",
       " ('abc', 3),\n",
       " ('a', 2),\n",
       " ('abcd', 1),\n",
       " ('abacde', 1),\n",
       " ('abcdefegbhifjkeedl', 1),\n",
       " ('ab', 1),\n",
       " ('abcdefag', 1),\n",
       " ('abcdeb', 1)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def patron(palabra):\n",
    "    letras = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    ind = 0\n",
    "    letra = letras[ind]\n",
    "    usadas = {}\n",
    "    patron = ''\n",
    "    for i in palabra:\n",
    "        if i not in usadas.keys():\n",
    "            usadas[i] = letra\n",
    "            ind += 1\n",
    "            letra = letras[ind]\n",
    "        patron += usadas[i]\n",
    "    return patron\n",
    "\n",
    "\n",
    "rdd = sc.textFile('foo.txt')\n",
    "rdd.flatMap(lambda x: x.split()).map(lambda x: (patron(x), 1)).reduceByKey(lambda x, y: x+y)\\\n",
    ".takeOrdered(10, lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('abcde', 3),\n",
       " ('abc', 3),\n",
       " ('a', 2),\n",
       " ('abcd', 1),\n",
       " ('abacde', 1),\n",
       " ('abcdefegbhifjkeedl', 1),\n",
       " ('ab', 1),\n",
       " ('abcdefag', 1),\n",
       " ('abcdeb', 1)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textFile = sc.textFile(\"foo.txt\")\n",
    "words = textFile.flatMap(lambda line: line.split())\n",
    "words.collect()\n",
    "def pattern(word):\n",
    "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    pat = ''\n",
    "    found = ''\n",
    "    for letter in word:\n",
    "        if letter in found:\n",
    "            pat += pat[found.index(letter)]\n",
    "        else:\n",
    "            found += letter\n",
    "            if len(found) > len(letters):\n",
    "                pat += '?'\n",
    "            else:\n",
    "                pat += letters[len(found)-1]\n",
    "    return pat\n",
    "   \n",
    "words.map(lambda x: (pattern(x), 1))\\\n",
    "     .reduceByKey(lambda x, y: x+y)\\\n",
    "     .takeOrdered(10, lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2015-02-2op\n",
    "Se tiene un RDD con libros en donde cada registro es un texto. Se\n",
    "pide obtener todos los anagramas de mas de 7 letras que puedan\n",
    "encontrarse. El formato de salida debe ser una lista de listas en donde\n",
    "cada lista tiene un conjunto de palabras que son anagramas. Ejemplo:\n",
    "[[discounter,introduces,reductions],[percussion,supersonic]...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'a2e3n2o1r1', [u'aeneanero']),\n",
       " (u'c1d1i2n2t2u1', [u'tincidunt']),\n",
       " (u'e2f1m2n1r1t1u1', [u'fermuentm', u'fermentum', u'fermtunme']),\n",
       " (u'c1e1i2l1r1s1t1u1', [u'ultricies']),\n",
       " (u'c1d1e1i1m2n2o1t1u1', [u'condimentum', u'condimentum']),\n",
       " (u'b1e1i1l1m1s1t1u2v1', [u'vestibulum'])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def anagrama(x):\n",
    "    res = {}\n",
    "    for i in x:\n",
    "        res[i] = res.get(i, 0) + 1\n",
    "    anagrama = ''\n",
    "    for letra, cant in sorted(res.items()):\n",
    "        anagrama += letra+str(cant)\n",
    "    return anagrama\n",
    "\n",
    "text = sc.textFile('bar.txt')\n",
    "text.flatMap(lambda x: x.split()).filter(lambda x: len(x) > 7)\\\n",
    "    .map(lambda x: (anagrama(x), x)).groupByKey().map(lambda x: (x[0], list(x[1]))).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2014-02-3op\n",
    "Se tiene un archivo de texto con datos de la forma (url_id,\n",
    "user_id) representando visitas a un website. (Se pueden\n",
    "repetir registros). Se pide programar en Pig un script que\n",
    "indique cual es el promedio global de sitios visitados por\n",
    "usuario. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1,\n",
       "  [('example.org', 0.3333333333333333),\n",
       "   ('example.net', 0.6666666666666666),\n",
       "   ('google.com', 0.3333333333333333)]),\n",
       " (2, [('example.org', 1.0), ('archlinux.org', 0.5)]),\n",
       " (3, [('google.com', 0.5), ('archlinux.org', 0.5)])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prom(x):\n",
    "    sites = set(x)\n",
    "    prom = []\n",
    "    for i in sites:\n",
    "        prom.append((i, float(x.count(i))/len(sites)))\n",
    "    return prom\n",
    "\n",
    "\n",
    "data = [('example.net', 1),\n",
    "       ('example.org', 1),\n",
    "       ('google.com', 1),\n",
    "       ('example.org', 2),\n",
    "       ('archlinux.org', 2),\n",
    "       ('example.net', 1),\n",
    "       ('example.org', 2),\n",
    "       ('archlinux.org', 3),\n",
    "       ('google.com', 3)]\n",
    "\n",
    "rdd = sc.parallelize(data)\n",
    "rdd.map(lambda x: (x[1], [x[0]])).reduceByKey(lambda x, y: x+y).map(lambda x: (x[0], prom(x[1]))).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 2015-02-1op\n",
    "Se tiene un RDD con las coordenadas de rectángulos de la forma\n",
    "(x1,x2,y1,y2).   Se   pide   programar   en   PySpark   un   programa   que\n",
    "encuentre el rectángulo de superficie mínima que contiene al punto\n",
    "(w,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0, 3, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sup(x):\n",
    "    return abs(x[0]-x[2])*abs(x[1]- x[3])\n",
    "\n",
    "data = [(0, 0, 3, 4),\n",
    "       (0, 0, 5, 4),\n",
    "       (1, 0, 3, 3),\n",
    "       (7, 8.5, 10, 10),\n",
    "       (2, 2, 6, 8),\n",
    "       (-1, -1, 3, 3),\n",
    "       (10, 10, 23, 24)]\n",
    "\n",
    "w, z = (1, 2)\n",
    "rdd = sc.parallelize(data)\n",
    "rdd.filter(lambda x: (w >= x[0] and w <= x[2]) and (z >= x[1] and z <= x[3]))\\\n",
    "    .reduce(lambda x, y: x if sup(x) < sup(y) else y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2015-01-1op\n",
    "Dada   una   colección   de   documentos   queremos   encontrar\n",
    "frases de 1 , 2 o 3 palabras que sean anagramas de otras. Por\n",
    "ejemplo: (“Postmaster”, “Stamp store”) o (“A telescope” , “To\n",
    "see Place”) o (“The cockroach”, “cook catch her”). Esta tarea\n",
    "implica una combinatoria muy difícil por lo que se decide usar\n",
    "Map-Reduce para paralelizarla. Usando Map-Reduce programar\n",
    "la   solución   a   este   problema   listando   todos   los   pares   de\n",
    "anagramas entre frases de 1, 2 o 3 palabras. Como puede\n",
    "verse en los ejemplos se ignoran mayúsculas y minúsculas y\n",
    "los espacios en blanco, puntuación, etc. Suponer que existe la\n",
    "función   word_tokenizer   que   recibe   un   texto   y   devuelve   un\n",
    "vector   de   palabras   ya   convertidas   a   minúsculas   y   sin\n",
    "puntuación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'e2f1m2n1r1t1u1', [u'fermuentm', u'fermentum', u'fermtunme']),\n",
       " (u'i2s1w1', [u'wisi', u'wisi', u'wisi']),\n",
       " (u'i1s1t1', [u'sit', u'sit', u'sit']),\n",
       " (u'a1e1r1t1', [u'erat', u'erat']),\n",
       " (u'a1e1i1m1s1t2', [u'sit amet', u'sit amet']),\n",
       " (u'a1e1i1t1v1', [u'vitae', u'vitae']),\n",
       " (u'a1b1e2i1l1m1r1s1t2u2v1', [u'vestibulum erat', u'erat bulumvesti']),\n",
       " (u'a1e1m1t1', [u'amet', u'amet']),\n",
       " (u'b1e1i1l1m1s1t1u2v1', [u'vestibulum', u'bulumvesti']),\n",
       " (u'c1d1e1i1m2n2o1t1u1', [u'condimentum', u'condimentum'])]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bar.txt no tiene palabras en mayusculas o con signos de puntuacion\n",
    "def ngrams(x, size):\n",
    "    words = x.split()\n",
    "    return [words[i:i+size] for i in xrange(len(words) - size + 1)]\n",
    "\n",
    "def anagrama(x):\n",
    "    res = {}\n",
    "    for i in x:\n",
    "        res[i] = res.get(i, 0) + 1\n",
    "    anagrama = ''\n",
    "    for letra, cant in sorted(res.items()):\n",
    "        anagrama += letra+str(cant)\n",
    "    return anagrama\n",
    "\n",
    "text = sc.textFile('bar.txt')\n",
    "text.flatMap(lambda x: [ngrams(x, i) for i in xrange(1, 4)]).flatMap(lambda x: x)\\\n",
    "    .map(lambda x: (anagrama(''.join(x)), ' '.join(x))).groupByKey()\\\n",
    "    .map(lambda x: (x[0], list(x[1]))).takeOrdered(10, lambda x: -len(x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
